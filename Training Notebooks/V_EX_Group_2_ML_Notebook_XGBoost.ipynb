{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9caIJabf-9y-",
        "YeKLBbCo9ufs",
        "ZAjT0ASiHDVf"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Code Required for All Models"
      ],
      "metadata": {
        "id": "9caIJabf-9y-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "Biz7kSkOGDM4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4tIUMSBmdfC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccf7f2bd-bd40-44ce-b41d-16f6400786de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.10/dist-packages (0.10.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.4.0)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.2.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "# Relevant imports\n",
        "!pip install scikit-optimize\n",
        "import xgboost as xgb\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from scipy.stats import uniform, randint\n",
        "from skopt import BayesSearchCV\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.impute import SimpleImputer\n",
        "from xgboost import plot_importance\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regressor Object"
      ],
      "metadata": {
        "id": "HTh8_RHiq86h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = xgb.XGBRegressor()"
      ],
      "metadata": {
        "id": "x-p3oFsWmtIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading data"
      ],
      "metadata": {
        "id": "FHfT5Q-DGEG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading csv file\n",
        "dataframe = pd.read_csv(\"./test_data.csv\")\n",
        "dataframe.head()\n",
        "\n",
        "\n",
        "k = 10  # Number of folds\n",
        "n = 10000 # Number of iterations"
      ],
      "metadata": {
        "id": "2t1euNtgnZ1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 1 - Coordinates Only"
      ],
      "metadata": {
        "id": "YeKLBbCo9ufs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selecting our features and targets, and converting them into DMatrices"
      ],
      "metadata": {
        "id": "WHrZATdU5u_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining features and targets\n",
        "X, y = dataframe.iloc[:, 1:3], dataframe[['LST']]\n",
        "\n",
        "# Splitting data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.1)\n",
        "\n",
        "# Converting the training and testing datasets into DMatrices\n",
        "dtrain_reg = xgb.DMatrix(X_train, y_train, enable_categorical=True)\n",
        "dtest_reg = xgb.DMatrix(X_test, y_test, enable_categorical=True)\n"
      ],
      "metadata": {
        "id": "b82CJ7Do-JJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating evaluation set and training model\n",
        "\n",
        "Testing model on the test data set after training\n"
      ],
      "metadata": {
        "id": "igrK3qEV5wIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimal parameters for Model 1 following Bayesian Search\n",
        "params = {\"objective\": \"reg:squarederror\", \"learning_rate\":0.0990999161353275, \"max_depth\": 3, \"min_child_weight\": 10, \"subsample\": 1, \"lambda\": 5, \"gamma\": 0, \"alpha\": 5, \"tree_method\":\"exact\", \"eta\":0}\n",
        "\n",
        "# K-FOLD CROSS VALIDATION\n",
        "results = xgb.cv(\n",
        "   params,\n",
        "   dtrain_reg,\n",
        "   num_boost_round = n,\n",
        "   nfold = k,\n",
        "   early_stopping_rounds = 100,\n",
        "   metrics = ['rmse', 'mae']\n",
        ")\n",
        "\n",
        "print(f\"Average RMSE: {results['test-rmse-mean'].mean()}\")\n",
        "print(f\"Average MAE: {results['test-mae-mean'].mean()}\")\n",
        "\n",
        "\n",
        "# Initialize KFold\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "# Convert the data to DMatrix format\n",
        "X_array = X.values\n",
        "y_array = y.values.flatten()\n",
        "\n",
        "r2_scores = []\n",
        "\n",
        "# Perform manual cross-validation\n",
        "for train_index, test_index in kf.split(X_array):\n",
        "    X_train, X_test = X_array[train_index], X_array[test_index]\n",
        "    y_train, y_test = y_array[train_index], y_array[test_index]\n",
        "\n",
        "    dtrain = xgb.DMatrix(X_train, y_train)\n",
        "    dtest = xgb.DMatrix(X_test, y_test)\n",
        "\n",
        "    # Train the model\n",
        "    booster = xgb.train(params, dtrain, num_boost_round=n)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = booster.predict(dtest)\n",
        "\n",
        "    # Calculate R-squared for this fold\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "# Calculate the average R-squared value\n",
        "average_r2 = np.mean(r2_scores)\n",
        "\n",
        "print(f\"Average R-Squared: {average_r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HlSxyX7o8dC",
        "outputId": "39a76b85-e854-4add-e410-889f34844ec6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average RMSE: 2.856462669051263\n",
            "Average MAE: 2.256796093009686\n",
            "Average R-Squared: 0.8211318065016574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model 2 - Coordinates and GLOBE Observer Labels only"
      ],
      "metadata": {
        "id": "ZAjT0ASiHDVf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining features and targets from csv"
      ],
      "metadata": {
        "id": "36ijocyIGOrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definining features and targets\n",
        "X, y = dataframe.iloc[:, 1:11], dataframe[['LST']] # USES ALL LAND COVER\n",
        "\n",
        "# Splitting data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.1)\n",
        "\n",
        "# Converting the training and testing datasets into DMatrices\n",
        "dtrain_reg = xgb.DMatrix(X_train, y_train, enable_categorical=True)\n",
        "dtest_reg = xgb.DMatrix(X_test, y_test, enable_categorical=True)"
      ],
      "metadata": {
        "id": "TAXVWxguoEY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross-validation"
      ],
      "metadata": {
        "id": "u8I2Z8tEGezq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\"objective\": \"reg:squarederror\", \"max_depth\": 50, \"lambda\": 5, \"alpha\": 4, \"tree_method\": \"exact\", \"eta\": 0, \"gamma\": 4, \"learning_rate\": 0.2351916922866857, \"min_child_weight\": 10, \"subsample\": 0.5789593986704742}\n",
        "\n",
        "results = xgb.cv(\n",
        "   params, dtrain_reg,\n",
        "   num_boost_round=n,\n",
        "   nfold = k,\n",
        "   early_stopping_rounds = 100,\n",
        "   metrics = {'rmse','mae'},\n",
        ")\n",
        "\n",
        "print(f\"Average RMSE: {results['test-rmse-mean'].mean()}\")\n",
        "print(f\"Average MAE: {results['test-mae-mean'].mean()}\")\n",
        "\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "# Convert the data to DMatrix format\n",
        "X_array = X.values\n",
        "y_array = y.values.flatten()\n",
        "\n",
        "r2_scores = []\n",
        "\n",
        "# Perform manual cross-validation\n",
        "for train_index, test_index in kf.split(X_array):\n",
        "    X_train, X_test = X_array[train_index], X_array[test_index]\n",
        "    y_train, y_test = y_array[train_index], y_array[test_index]\n",
        "\n",
        "    dtrain = xgb.DMatrix(X_train, y_train)\n",
        "    dtest = xgb.DMatrix(X_test, y_test)\n",
        "\n",
        "    # Train the model\n",
        "    booster = xgb.train(params, dtrain, num_boost_round=n)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = booster.predict(dtest)\n",
        "\n",
        "    # Calculate R-squared for this fold\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "# Calculate the average R-squared value\n",
        "average_r2 = np.mean(r2_scores)\n",
        "\n",
        "print(f\"Average R-Squared: {average_r2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqINCIwL8KgY",
        "outputId": "a4a7bbe6-b854-4013-be71-c453a2c1753e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average RMSE: 3.0139600952821866\n",
            "Average MAE: 2.326997339874897\n",
            "Average R-Squared: 0.7868356040375915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model 3 - Coordinates, GLOBE Observer, CEO Labels"
      ],
      "metadata": {
        "id": "GFmxwgEztiXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = dataframe.iloc[:, 1:26].drop(dataframe.columns[11], axis=1), dataframe[['LST']]\n",
        "\n",
        "# Splitting data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.1)\n",
        "\n",
        "# Converting the training and testing datasets into DMatrices\n",
        "dtrain_reg = xgb.DMatrix(X_train, y_train, enable_categorical=True)\n",
        "dtest_reg = xgb.DMatrix(X_test, y_test, enable_categorical=True)"
      ],
      "metadata": {
        "id": "AdrufsmltlmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross-validation"
      ],
      "metadata": {
        "id": "5DqB28iDty82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\"objective\": \"reg:squarederror\"}#, \"max_depth\": 3, \"lambda\": 1, \"alpha\": 0, \"tree_method\": \"exact\", \"eta\": 0, \"gamma\": 0, \"learning_rate\": 0.09447565846479973, \"min_child_weight\": 10, \"subsample\": 1.0}\n",
        "\n",
        "results = xgb.cv(\n",
        "   params, dtrain_reg,\n",
        "   num_boost_round=n,\n",
        "   nfold = k,\n",
        "   early_stopping_rounds = 100,\n",
        "   metrics = {'rmse','mae'},\n",
        ")\n",
        "\n",
        "\n",
        "print(f\"Average RMSE: {results['test-rmse-mean'].mean()}\")\n",
        "print(f\"Average MAE: {results['test-mae-mean'].mean()}\")\n",
        "\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "# Convert the data to DMatrix format\n",
        "X_array = X.values\n",
        "y_array = y.values.flatten()\n",
        "\n",
        "r2_scores = []\n",
        "\n",
        "# Perform manual cross-validation\n",
        "for train_index, test_index in kf.split(X_array):\n",
        "    X_train, X_test = X_array[train_index], X_array[test_index]\n",
        "    y_train, y_test = y_array[train_index], y_array[test_index]\n",
        "\n",
        "    dtrain = xgb.DMatrix(X_train, y_train)\n",
        "    dtest = xgb.DMatrix(X_test, y_test)\n",
        "\n",
        "    # Train the model\n",
        "    booster = xgb.train(params, dtrain, num_boost_round=n)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = booster.predict(dtest)\n",
        "\n",
        "    # Calculate R-squared for this fold\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "# Calculate the average R-squared value\n",
        "average_r2 = np.mean(r2_scores)\n",
        "print(f\"Average R-Squared: {average_r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgXq7Irut0oj",
        "outputId": "d98be7ab-c4d8-485a-9b5d-147a0fe044bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average RMSE: 2.9003299179770363\n",
            "Average MAE: 2.1310074205354397\n",
            "Average R-Squared: 0.8030478361103602\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sample of Bayesian Search used to optimize all three models.\n",
        "Move code cell accordingly depending on which model you would like to optimize"
      ],
      "metadata": {
        "id": "Ql2SPnHZzMNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_space = {\n",
        "    'learning_rate': (0.01, 0.3, 'uniform'),\n",
        "    'max_depth': (3, 50),\n",
        "    'subsample': (0.1, 1.0),\n",
        "    'min_child_weight': (1, 10),\n",
        "    'gamma': (0, 10),\n",
        "    'alpha': (0, 10),\n",
        "    'eta': (0, 1),\n",
        "    'lambda': (0, 5),\n",
        "\n",
        "}\n",
        "\n",
        "bayes_search = BayesSearchCV(\n",
        "    estimator=xgb.XGBRegressor(),\n",
        "    search_spaces=param_space,\n",
        "    n_iter=100,\n",
        "    cv=10,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    n_jobs=-1,\n",
        "    verbose=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "bayes_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"{bayes_search.best_params_}\")"
      ],
      "metadata": {
        "id": "SZPXFwpPy7y9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f14ec51-2227-4030-e7b2-49b34254d8e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
            "OrderedDict([('alpha', 0), ('eta', 0), ('gamma', 0), ('lambda', 1), ('learning_rate', 0.09447565846479973), ('max_depth', 3), ('min_child_weight', 10), ('subsample', 1.0)])\n"
          ]
        }
      ]
    }
  ]
}